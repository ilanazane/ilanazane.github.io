<!DOCTYPE html>
<html lang="en"><head>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Summary: Vision Transformers are Good Mask Auto-Labelers | Ilana Zane</title>
<meta name="generator" content="Jekyll v4.3.3" />
<meta property="og:title" content="Summary: Vision Transformers are Good Mask Auto-Labelers" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="A blog about AI and other interests" />
<meta property="og:description" content="A blog about AI and other interests" />
<link rel="canonical" href="http://localhost:4000/2023/01/12/MAL.html" />
<meta property="og:url" content="http://localhost:4000/2023/01/12/MAL.html" />
<meta property="og:site_name" content="Ilana Zane" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2023-01-12T00:00:00-05:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Summary: Vision Transformers are Good Mask Auto-Labelers" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2023-01-12T00:00:00-05:00","datePublished":"2023-01-12T00:00:00-05:00","description":"A blog about AI and other interests","headline":"Summary: Vision Transformers are Good Mask Auto-Labelers","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/2023/01/12/MAL.html"},"url":"http://localhost:4000/2023/01/12/MAL.html"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/main.css"><link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="Ilana Zane" /><meta name="google-site-verification" content="-U80l7j-jWyXzli0lOaeIKs8E0K3Rs2hUzeXIwJeoaw" />
  </head>

  <script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    processEscapes: true
  }
});
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script><body><header class="site-header" role="banner">

    <div class="wrapper"><a class="site-title" rel="author" href="/">Ilana Zane</a><nav class="site-nav">
          <input type="checkbox" id="nav-trigger" class="nav-trigger" />
          <label for="nav-trigger">
            <span class="menu-icon">
              <svg viewBox="0 0 18 15" width="18px" height="15px">
                <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
              </svg>
            </span>
          </label>
  
          <div class="trigger"><a class="page-link" href="/about/">About</a><a class="page-link" href="/categories/">Categories</a><a class="page-link" href="/research/">Research</a></div>
        </nav><!-- <img src="/assets/images/banner2.png"/> -->
    </div>
  </header>
  <main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Summary: Vision Transformers are Good Mask Auto-Labelers</h1>
    <p class="post-meta">
      <time class="dt-published" datetime="2023-01-12T00:00:00-05:00" itemprop="datePublished">Jan 12, 2023
      </time></p>
  </header>

  <div class="post-content e-content" itemprop="articleBody">
    <p><img src="http://localhost:4000/assets/images/MAL_files/front.png" alt="image" /></p>

<p>In a <a href="https://arxiv.org/abs/2301.03992"> new paper </a> published on January 10th 2023, researchers from NVIDIA, Meta AI, FAIR, Fudan University, and Caltech, propose MAL: a Mask Auto-Labeler that has results that surpass those of current state of the art methods. 
This was a pretty interesting paper and I learned a lot about computer vision. I think the best way to learn any subject is to read a paper and just start by figuring out what all of the acronyms stand for… so many acronyms…</p>

<p>Let us summarize:</p>

<h2>The Issue</h2>
<p>Right now in computer vision, there is a lot of data that needs to be labeled and segmented for tasks such as detecting other cars, people, stop signs for autonomous driving, for example. A lot of this data is labeled and masked by humans and can result in a lot of errors if there is not quality control. Creating the COCO dataset required 55,000 hours of human work and this doesn’t guarantee that the labeling and masking is even correct.</p>

<p>Models that use data labeled by humans are considered fully supervised. However, there is another method called box-supervised learning, which Lan et al use in their work.</p>

<h2>Methodology</h2>
<p>The authors of this paper propose a model called MAL, Mask Auto-Labeler, which is essentially based on vision transformers. MAL is a two phase framework that has a mask auto-labeling phase and an instance segmentation training phase.
From what I understand, this means that MAL generates the masks for input images and then the training (second) phase consists of training well known vision models to do image segmentation tasks using the MAL generated masks and see how they perform compared to their fully supervised versions.</p>
<h1>Why RoI</h1>
<p>Before we get into anything, let’s discuss the input data. Previous research on the topic of box-supervised training has used entire images, but MAL uses RoI (Region of Interest) images. It’s beneficial to use RoI images in this scenario for two reasons: 
    1. RoI images are good at handling small objects because the images are already enlarged and this can avoid issues caused by low resolution. 
    2. RoI images allow MAL to focus on the segmentation task on hand— this prevents the model from becoming distracted with tasks such as object detection. 
Here is an example of an RoI image. I was confused for some time on the difference between RoI and bounding boxes—  they are not the same! Bounding boxes create the smallest box possible around an object, an RoI is a hypothetical area that is usually denoted with a box in other research papers and blogs.</p>

<p><img src="http://localhost:4000/assets/images/MAL_files/ROI.jpeg" alt="image" /></p>

<h1>How to get RoI</h1>
<p>Once the RoI is obtained, the model has a zoomed in image of what needs to be segmented and it doesn’t have to look for other objects in the image to be segmented. 
In order to get the RoI, bounding boxes are randomly expanded to include background pixels, where negative bags are chosen from expanded rows and columns (later on this). This is an essential method for MAL, because it will otherwise learn trivial solutions and generated masks will fill the entire bounding box.</p>

<h2>MAL Architecture</h2>

<p><img src="http://localhost:4000/assets/images/MAL_files/training.png" alt="image" /></p>

<p>The MAL model consists of two symmetric networks: an image encoder and a mask decoder. The image encoder is a standard Vision Transformer (ViT). Some of the ViT’s that were used for comparison were: 
    1. ConvNeXts with Cascade R-CNN 
    2. Swin Transformers with Mask2Former 
    3. ResNets and ResNeXts with SOLOv2 
The mask decoder is a simple attention based network inspired by YOLACT, a real-time instance segmentation model. 
Loss is measured with Multiple Instance Learning (MIL) loss. Once the mask is generated, each pixel in the output has a respective mask score. Within the image, each row/ column of pixels is considered to be a bag. Each bag will be positive or negative depending on the overall mask score of the pixels in that row/ column. Don’t quote me on this lol. My guess is that negative bags are considered to be outside of the mask and positive bags denote the RoI within bounds.</p>

<h2>Results</h2>
<p>The authors of this paper found that the instance segmentation models that they used with the MAL generated masks achieved up to 97.4% of their fully supervised performance on the COCO and LVIS datasets.</p>

<p><img src="http://localhost:4000/assets/images/MAL_files/results.png" alt="image" /></p>

<p>Overall, this approach narrows down the error gap between box-supervised and fully-supervised approaches. Currently, MAL outperforms all state-of-the-art box-supervised instance segmentation methods by a significant margin. Future work involves improving the model where there are overlapping RoI’s (occlusion issue).</p>


  </div><a class="u-url" href="/2023/01/12/MAL.html" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <h2 class="footer-heading">Ilana Zane</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">Ilana Zane</li><li><a class="u-email" href="mailto:ilanazane@comcast.net">ilanazane@comcast.net</a></li></ul>
      </div>

      <div class="footer-col footer-col-2"><ul class="social-media-list"><li><a href="https://github.com/ilanazane"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg> <span class="username">ilanazane</span></a></li><li><a href="https://instagram.com/lanadelzane"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#instagram"></use></svg> <span class="username">lanadelzane</span></a></li></ul>
</div>

      <div class="footer-col footer-col-3">
        <p>A blog about AI and other interests </p>
      </div>
    </div>

  </div>

</footer>
</body>

</html>
